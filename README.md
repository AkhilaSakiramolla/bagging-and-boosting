# Spam email classfication

Implementation of bagging and boosting (AdaBoost) algorithms on spam dataset (https://archive.ics.uci.edu/ml/datasets/spambase) to classify email messages as spam or ham. The aim here is to to compare the algorithms, and to try to figure out which algorithm
is most effective when, and why. For this, I looked at how the test error evolves as a function of the number
of rounds and checked for overfitting. I have also implemented the algorithms on other datasets like letter recognition dataset (https://archive.ics.uci.edu/ml/datasets/letter+recognition) and German credit dataset (https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data) to run experiments and evaluate the models. 

Refer to the IPYNB file for detailed explanation!

